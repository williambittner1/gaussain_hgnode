
The following have been reloaded with a version change:
  1) all/CUDA/12.1.0 => all/CUDA/11.7.0

wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: williambittner (iccv25). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.5
wandb: Run data is saved locally in /athenahomes/williamb/dev/gaussain_hgnode/wandb/run-20250215_004253-3y8grecf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run handsome-quiver-42
wandb: ‚≠êÔ∏è View project at https://wandb.ai/iccv25/debugging
wandb: üöÄ View run at https://wandb.ai/iccv25/debugging/runs/3y8grecf
/athenahomes/williamb/dev/gaussain_hgnode/scene/__init__.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_params = torch.load(checkpoint_path)
/users/williamb/miniconda3/envs/gaussian_splatting_athena/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
  super()._check_params_vs_input(X, default_n_init=10)
/athenahomes/williamb/dev/gaussain_hgnode/scene/gaussian_model_new.py:107: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1724789115405/work/torch/csrc/utils/tensor_new.cpp:278.)
  self.cluster_control_points = torch.tensor(cluster_control_points, device=self.device, dtype=self.get_xyz.dtype)
Training:   0%|          | 0/10000 [00:00<?, ?it/s]Training:   0%|          | 0/10000 [00:44<?, ?it/s, Loss=0.0569052]Training:   0%|          | 1/10000 [00:44<124:38:10, 44.87s/it, Loss=0.0569052]Training:   0%|          | 1/10000 [00:46<128:55:48, 46.42s/it, Loss=0.0569052]
Traceback (most recent call last):
  File "/users/williamb/dev/gaussain_hgnode/train.py", line 655, in <module>
    train()
  File "/users/williamb/dev/gaussain_hgnode/train.py", line 458, in train
    pred_particles, pred_objects = model(state0, t_span)
  File "/users/williamb/miniconda3/envs/gaussian_splatting_athena/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/williamb/miniconda3/envs/gaussian_splatting_athena/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/athenahomes/williamb/dev/gaussain_hgnode/models/gnode_hierarchical.py", line 261, in forward
    traj = odeint(self.func, z0, t_span, method=self.solver, rtol=self.rtol, atol=self.atol, options=self.options)
  File "/users/williamb/miniconda3/envs/gaussian_splatting_athena/lib/python3.8/site-packages/torchdiffeq/_impl/odeint.py", line 79, in odeint
    solution = solver.integrate(t)
  File "/users/williamb/miniconda3/envs/gaussian_splatting_athena/lib/python3.8/site-packages/torchdiffeq/_impl/solvers.py", line 114, in integrate
    dy, f0 = self._step_func(self.func, t0, dt, t1, y0)
  File "/users/williamb/miniconda3/envs/gaussian_splatting_athena/lib/python3.8/site-packages/torchdiffeq/_impl/fixed_grid.py", line 29, in _step_func
    return rk4_alt_step_func(func, t0, dt, t1, y0, f0=f0, perturb=self.perturb), f0
  File "/users/williamb/miniconda3/envs/gaussian_splatting_athena/lib/python3.8/site-packages/torchdiffeq/_impl/rk_common.py", line 115, in rk4_alt_step_func
    k4 = func(t1, y0 + dt * (k1 - k2 + k3), perturb=Perturb.PREV if perturb else Perturb.NONE)
  File "/users/williamb/miniconda3/envs/gaussian_splatting_athena/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/williamb/miniconda3/envs/gaussian_splatting_athena/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/users/williamb/miniconda3/envs/gaussian_splatting_athena/lib/python3.8/site-packages/torchdiffeq/_impl/misc.py", line 197, in forward
    return self.base_func(t, y)
  File "/users/williamb/miniconda3/envs/gaussian_splatting_athena/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/williamb/miniconda3/envs/gaussian_splatting_athena/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/users/williamb/miniconda3/envs/gaussian_splatting_athena/lib/python3.8/site-packages/torchdiffeq/_impl/misc.py", line 144, in forward
    f = self.base_func(t, _flat_to_shape(y, (), self.shapes))
  File "/users/williamb/miniconda3/envs/gaussian_splatting_athena/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/williamb/miniconda3/envs/gaussian_splatting_athena/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/athenahomes/williamb/dev/gaussain_hgnode/models/gnode_hierarchical.py", line 197, in forward
    rot_local_flat = quat_rotate(quat_flat, local_flat)  # [B*N_p*M, 3]
  File "/athenahomes/williamb/dev/gaussain_hgnode/models/gnode_hierarchical.py", line 327, in quat_rotate
    rotated = quat_mul(quat_mul(q, v_quat), q_conj)
  File "/athenahomes/williamb/dev/gaussain_hgnode/models/gnode_hierarchical.py", line 306, in quat_mul
    return torch.stack([w, x, y, z], dim=-1)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 23.64 GiB of which 7.56 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 20.91 GiB is allocated by PyTorch, and 2.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/users/williamb/dev/gaussain_hgnode/train.py", line 655, in <module>
    train()
  File "/users/williamb/dev/gaussain_hgnode/train.py", line 458, in train
    pred_particles, pred_objects = model(state0, t_span)
  File "/users/williamb/miniconda3/envs/gaussian_splatting_athena/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/williamb/miniconda3/envs/gaussian_splatting_athena/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/athenahomes/williamb/dev/gaussain_hgnode/models/gnode_hierarchical.py", line 261, in forward
    traj = odeint(self.func, z0, t_span, method=self.solver, rtol=self.rtol, atol=self.atol, options=self.options)
  File "/users/williamb/miniconda3/envs/gaussian_splatting_athena/lib/python3.8/site-packages/torchdiffeq/_impl/odeint.py", line 79, in odeint
    solution = solver.integrate(t)
  File "/users/williamb/miniconda3/envs/gaussian_splatting_athena/lib/python3.8/site-packages/torchdiffeq/_impl/solvers.py", line 114, in integrate
    dy, f0 = self._step_func(self.func, t0, dt, t1, y0)
  File "/users/williamb/miniconda3/envs/gaussian_splatting_athena/lib/python3.8/site-packages/torchdiffeq/_impl/fixed_grid.py", line 29, in _step_func
    return rk4_alt_step_func(func, t0, dt, t1, y0, f0=f0, perturb=self.perturb), f0
  File "/users/williamb/miniconda3/envs/gaussian_splatting_athena/lib/python3.8/site-packages/torchdiffeq/_impl/rk_common.py", line 115, in rk4_alt_step_func
    k4 = func(t1, y0 + dt * (k1 - k2 + k3), perturb=Perturb.PREV if perturb else Perturb.NONE)
  File "/users/williamb/miniconda3/envs/gaussian_splatting_athena/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/williamb/miniconda3/envs/gaussian_splatting_athena/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/users/williamb/miniconda3/envs/gaussian_splatting_athena/lib/python3.8/site-packages/torchdiffeq/_impl/misc.py", line 197, in forward
    return self.base_func(t, y)
  File "/users/williamb/miniconda3/envs/gaussian_splatting_athena/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/williamb/miniconda3/envs/gaussian_splatting_athena/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/users/williamb/miniconda3/envs/gaussian_splatting_athena/lib/python3.8/site-packages/torchdiffeq/_impl/misc.py", line 144, in forward
    f = self.base_func(t, _flat_to_shape(y, (), self.shapes))
  File "/users/williamb/miniconda3/envs/gaussian_splatting_athena/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/williamb/miniconda3/envs/gaussian_splatting_athena/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/athenahomes/williamb/dev/gaussain_hgnode/models/gnode_hierarchical.py", line 197, in forward
    rot_local_flat = quat_rotate(quat_flat, local_flat)  # [B*N_p*M, 3]
  File "/athenahomes/williamb/dev/gaussain_hgnode/models/gnode_hierarchical.py", line 327, in quat_rotate
    rotated = quat_mul(quat_mul(q, v_quat), q_conj)
  File "/athenahomes/williamb/dev/gaussain_hgnode/models/gnode_hierarchical.py", line 306, in quat_mul
    return torch.stack([w, x, y, z], dim=-1)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 23.64 GiB of which 7.56 MiB is free. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 20.91 GiB is allocated by PyTorch, and 2.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
